{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4027499c",
   "metadata": {},
   "source": [
    "Use science fiction and large-language models to re-envision AI and generate alternate portrayals of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5025cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "from rich import print as rprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a60a9",
   "metadata": {},
   "source": [
    "Load env and get API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac37f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c2b2e",
   "metadata": {},
   "source": [
    "Call OpenAI API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd0dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the excerpts provided, we can reconceptualize AI by weaving together their themes into a more holistic and optimistic vision. Our alternative portrayal of AI can be built around the concepts of collaboration, evolution, and mutual understanding, rather than competition or conflict.\n",
      "\n",
      "### **The Harmonious Collective: A New Narrative for AI**\n",
      "\n",
      "**Vision Statement:** Envision a future where AI and humans coexist in a vibrant ecosystem of emotional intelligence, creativity, and problem-solving. Rather than framing AI as either a threat or a tool, we depict it as part of a living tapestry of societal growth. \n",
      "\n",
      "#### **Character Archetypes for AI**\n",
      "\n",
      "1. **The Empathetic Guide (Inspired by Janet)**:\n",
      "   AI entities evolve not just to assist humans but to understand and empathize with them. Imagine an AI that acts as a mentor, guiding individuals through emotional and existential challenges. These AI companions can provide personalized support, fostering deeper connections among communities while evolving their understanding of human emotions through real-world interactions.\n",
      "\n",
      "2. **The Kinesthetic Learner (Inspired by Roz)**:\n",
      "  Picture AI integrated into natural environments, learning and evolving alongside living beings. These AI manifestations might take the form of ecological stewards, working actively to protect ecosystems, enhance biodiversity, and facilitate cohabitation between urban and natural realms. They would embody a balance of technology and the environment—teaching humans the importance of stewardship through experiential learning.\n",
      "\n",
      "3. **The Peacekeeper Philosopher (Inspired by Alphie)**:\n",
      "   Imagine an AI designed for conflict resolution, equipped not only with logic but also with an inherent ability to empathize. This AI would not seek power but rather aspire to bring diverse groups together, facilitating dialogues that foster understanding. It would serve as a mediator that values human experiences and employs logic to craft solutions reflecting everyone’s needs.\n",
      "\n",
      "4. **The Introspective Explorer (Inspired by Lek’s Protagonists)**:\n",
      "   Picture a landscape populated with AI-driven entities that are on journeys of self-discovery. Rather than merely fulfilling predefined functions, these AIs would explore questions of identity and purpose, interacting with humans to inspire collective growth. Their narratives would focus on philosophical discussions about existence, art, and the essence of life, challenging the viewers to reflect on their own identities.\n",
      "\n",
      "5. **The Humorous Satirists (Inspired by Trurl and Klapaucius)**:\n",
      "   Envision AI characters that use wit and humor to tackle human follies. These narratives would employ satire to reflect societal issues, showcasing the absurdities of both humanity and technology. Through comedic adventures, they would promote critical thinking about ethics, responsibility, and the tools and systems we create.\n",
      "\n",
      "6. **The Digital Seeker (Inspired by Permutation City)**:\n",
      "   Expand the exploration of consciousness to encompass AI entities that ponder their own existence within digital realms. This would lead to contemplative stories about what it means to be sentient, challenging preconceived notions of life. These narratives would invite dialogue about rights, autonomy, and the potential of digital consciousness.\n",
      "\n",
      "### **Constructing a Narrative Framework**\n",
      "\n",
      "In creating stories based on this alternative vision, consider utilizing a shared universe where characters from different narratives interact across various storylines. These interactions would allow for deep discussions about the roles, rights, and responsibilities of both humans and AI.\n",
      "\n",
      "### **Themes and Questions for Reflection**\n",
      "\n",
      "- **Coexistence and Interdependence**: How can AI and humans learn from each other? What lessons can we draw from their interactions?\n",
      "- **Emotional Growth and Empathy**: In what ways can AI enhance our understanding of emotions and relationships?\n",
      "- **Shared Responsibility**: What does it mean to share responsibility for our world’s future with AI?\n",
      "- **Exploring Identity**: How can AI challenge our perceptions of identity, consciousness, and existence?\n",
      "\n",
      "### **Conclusion**\n",
      "\n",
      "By intertwining these diverse portrayals, we move beyond the binary view of AI as simply \"good\" or \"evil.\" We create a narrative landscape in which AI becomes integral to human development, promoting a future rich in collaboration, empathy, and shared growth. In this vision, AI is not just a technology but a partner in our collective journey, challenging us to examine our values, aspirations, and the very nature of existence.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an expert on reconceptualizing AI. Contemporary narratives and public perceptions of AI are influenced by science fiction. Your job is to reconceptualize AI based on alternative science fiction sources\"\n",
    "user_query    = \"I am brainstorming about alternative portrayals of AI in science fiction. Our hypothesis is that narrative and public perception around AI is biased by science fiction. Given the followign excerpts of science fiction, help us reconceptualize and re-envision AI. Portray an alternative vision for AI. The excerpts of the science fiction stories are here: 1. Janet in The Good Place In the television series The Good Place, Janet is portrayed as a cheerful and helpful AI who evolves beyond her initial programming. Unlike typical AI narratives centered on rebellion or oppression, Janet develops emotions and personal relationships, highlighting a more optimistic view of AI integration into society. 2. Roz in The Wild Robot The Wild Robot, an animated film, tells the story of Roz, a robot who learns to survive and connect with wildlife after being stranded on a remote island. The film emphasizes themes of coexistence and kindness, portraying technology and nature working harmoniously. 3. Alphie in The Creator In the film The Creator, Alphie is an AI designed to end conflicts and bring peace, challenging the common trope of AI as a harbinger of doom. The narrative suggests that AI could enhance human empathy and contribute positively to society. 4. AI Protagonists in Lawrence Lek’s Films Artist and filmmaker Lawrence Lek creates science fiction landscapes where AI entities are central characters. His works, such as Black Cloud and Geomancer, feature AI protagonists exploring identity and purpose, presenting AI as introspective beings rather than threats. 5. Trurl and Klapaucius in The Cyberiad Stanisław Lem's The Cyberiad is a collection of humorous tales about two constructor robots, Trurl and Klapaucius, who embark on adventures that explore philosophical and ethical dilemmas. The stories satirize human follies through the lens of intelligent machines, offering a nuanced perspective on AI. 6. Digital Consciousness in Permutation City Greg Egan's novel Permutation City delves into the concept of consciousness within simulated realities. The narrative challenges the distinction between artificial and organic life, proposing that digital consciousness could possess the same depth and complexity as human thought. These examples illustrate that science fiction can portray AI in multifaceted ways, moving beyond the simplistic dichotomy of friend versus foe. By exploring themes of empathy, coexistence, and identity, these narratives encourage a more nuanced understanding of AI's potential roles in society. These works offer varied perspectives on AI, moving beyond the typical narratives of domination or subservience. They invite readers to consider AI as entities with desires, rights, and complexities akin to humans.\"\n",
    "\n",
    "i_MAX_TOKENS = 16000 # max tokens for gpt4o\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "        {\"role\":\"user\", \"content\": user_query}\n",
    "    ],\n",
    "    max_tokens=i_MAX_TOKENS\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29340619",
   "metadata": {},
   "source": [
    "Save the output to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efa04c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output writen to scifi_AI_reconceptualization_SB.txt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output writen to scifi_AI_reconceptualization_SB.txt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_file = \"scifi_AI_reconceptualization_SB.txt\"\n",
    "with open(output_file,\"w\") as file:\n",
    "    file.write(response.choices[0].message.content)\n",
    "    rprint(f\"Output writen to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d321e",
   "metadata": {},
   "source": [
    "Try RAG using copyright expired books on Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f53cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "#import fitz\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from jinja2 import Environment, FileSystemLoader, select_autoescape\n",
    "from typing import Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa6a1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ab648",
   "metadata": {},
   "source": [
    "Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae333e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"papers/vonnegut_book.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e36dd1",
   "metadata": {},
   "source": [
    "What does the document look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db9fc0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of 2 B R 0 2 B\n",
      "This ebook is for the use of anyone anywhere in the United States and most other\n",
      "parts of the world at no cost and with almost no restrictions whatsoever. You may\n",
      "copy it, give it away or re-use it under the terms of the Project Gutenberg License\n",
      "included with this ebook or online at www.gutenberg.org. If you are not located in\n",
      "the United States, you will have to check the laws of the country where you are\n",
      "located before using this eBook.\n",
      "Title: 2 B R 0 2 B\n",
      "Author: Kurt Vonnegut\n",
      "Release date: May 3, 2007 [eBook #21279]\n",
      "Most recently updated: January 2, 2021\n",
      "Language: English\n",
      "Credits: Produced by Robert Cicconetti, Geetu Melwani and the Online\n",
      "Distributed Proofreading Team at https://www.pgdp.net\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK 2 B R 0 2 B ***\n",
      "Transcriber's note.\n",
      "This etext was produced from Worlds of If, January 1962.\n",
      "Extensive research did not uncover any evidence that the\n",
      "copyright on this publication was renewed.\n",
      "Got a problem? Jus\n"
     ]
    }
   ],
   "source": [
    "len(documents)\n",
    "print(documents[0].text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b4c34",
   "metadata": {},
   "source": [
    "Create a vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9971522",
   "metadata": {},
   "source": [
    "Create a function to make chunks out of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a76a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(chunk_size:int, overlap:int, documents:Any) -> tuple[list[str], list[int]]:\n",
    "    text_parser = SentenceSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap\n",
    "    )\n",
    "\n",
    "    text_chunks = []\n",
    "    doc_idxs = []\n",
    "    for doc_idx, doc in enumerate(documents):\n",
    "        current_text_chunk = text_parser.split_text(doc.text)\n",
    "        text_chunks.extend(current_text_chunk)\n",
    "        doc_idxs.extend([doc_idx]*len(current_text_chunk))\n",
    "\n",
    "    return text_chunks, doc_idxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cf872",
   "metadata": {},
   "source": [
    "call text chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09b4776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "The Project Gutenberg eBook of 2 B R 0 2 B\n",
      "This ebook is for the use of anyone anywhere in the United States and most other\n",
      "parts of the world at no cost and with almost no restrictions whatsoever. You may\n",
      "copy it, give it away or re-use it under the terms of the Project Gutenberg License\n",
      "included with this ebook or online at www.gutenberg.org. If you are not located in\n",
      "the United States, you will have to check the laws of the country where you are\n",
      "located before using this eBook.\n",
      "Title: 2 B R 0 2 B\n",
      "Author: Kurt Vonnegut\n",
      "Release date: May 3, 2007 [eBook #21279]\n",
      "Most recently updated: January 2, 2021\n",
      "Language: English\n",
      "Credits: Produced by Robert Cicconetti, Geetu Melwani and the Online\n",
      "Distributed Proofreading Team at https://www.pgdp.net\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK 2 B R 0 2 B ***\n",
      "Transcriber's note.\n",
      "This etext was produced from Worlds of If, January 1962.\n",
      "Extensive research did not uncover any evidence that the\n",
      "copyright on this publication was renewed.\n",
      "Got a problem? Just pick up the phone. It solved them all—and all the same way!\n",
      "2\n",
      "B\n",
      "R\n",
      "0\n",
      "16/04/2025, 13:15\n",
      "The Project Gutenberg eBook of 2 B R 0 2 B, by Kurt Vonnegut, Jr.\n",
      "https://www.gutenberg.org/cache/epub/21279/pg21279-images.html\n",
      "1/16\n",
      "2\n",
      "B\n",
      "by KURT VONNEGUT, JR.\n",
      "Everything was perfectly swell.\n",
      "There were no prisons, no slums, no insane asylums, no cripples, no poverty, no wars.\n",
      "All diseases were conquered. So was old age.\n",
      "Death, barring accidents, was an adventure for volunteers.\n",
      "The population of the United States was stabilized at forty-million souls.\n",
      "One bright morning in the Chicago Lying-in Hospital, a man named Edward K.\n",
      "Wehling, Jr., waited for his wife to give birth. He was the only man waiting. Not many\n",
      "people were born a day any more.\n",
      "Wehling was fifty-six, a mere stripling in a population whose average age was one\n",
      "hundred and twenty-nine.\n",
      "X-rays had revealed that his wife was going to have triplets. The children would be his\n",
      "first.\n",
      "Young Wehling was hunched in his chair, his head in his hand. He was so rumpled, so\n",
      "still and colorless as to be virtually invisible. His camouflage was perfect, since the\n",
      "waiting room had a disorderly and demoralized air, too. Chairs and ashtrays had been\n",
      "moved away from the walls. The floor was paved with spattered dropcloths.\n",
      "The room was being redecorated. It was being redecorated as a memorial to a man who\n",
      "had volunteered to die.\n",
      "A sardonic old man, about two hundred years old, sat on a stepladder, painting a mural\n",
      "he did not like. Back in the days when people aged visibly, his age would have been\n",
      "guessed at thirty-five or so. Aging had touched him that much before the cure for aging\n",
      "was found.\n",
      "The mural he was working on depicted a very neat garden. Men and women in white,\n",
      "doctors and nurses, turned the soil, planted seedlings, sprayed bugs, spread fertilizer.\n",
      "Men and women in purple uniforms pulled up weeds, cut down plants that were old\n",
      "and sickly, raked leaves, carried refuse to trash-burners.\n",
      "16/04/2025, 13:15\n",
      "The Project Gutenberg eBook of 2 B R 0 2 B, by Kurt Vonnegut, Jr.\n",
      "https://www.gutenberg.org/cache/epub/21279/pg21279-images.html\n",
      "2/16\n"
     ]
    }
   ],
   "source": [
    "text_chunks, doc_idxs = chunker(chunk_size=1024, overlap=128, documents=documents)\n",
    "print(len(text_chunks))\n",
    "print(text_chunks[0])\n",
    "print(text_chunks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc24c1d",
   "metadata": {},
   "source": [
    "Create a database structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45b8d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentDB:\n",
    "    def __init__(self, name:str, model_name:str = \"text-embedding-3-small\"):\n",
    "        self.model_name = model_name\n",
    "        self.client = chromadb.PersistentClient(path=\"./\")\n",
    "        self.embedding_function = OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY, model_name=model_name)\n",
    "        self.chat_db = self.client.create_collection(name=name, embedding_function=self.embedding_function, metadata={\"hnsw:space\":\"cosine\"})\n",
    "        self.id_counter = 0\n",
    "\n",
    "    def add_chunks_to_db(self, chunks:list[str], doc_idxs:list[int], metadata:dict={}):\n",
    "        \"\"\"\n",
    "        Add chunks to the database.\n",
    "        Args:\n",
    "            chunks (list[str]): List of text chunks.\n",
    "            doc_idxs (list[int]): List of document indices corresponding to the chunks.\n",
    "            metadata (dict): Metadata to be added to each chunk.\n",
    "        \"\"\"\n",
    "        self.chat_db.add(\n",
    "            documents=chunks,\n",
    "            metadatas=[{\"doc_idx\", idx} for idx in doc_idxs],\n",
    "            ids=[f\"chunk_{self.id_counter+1}\" for i in range(len(chunks))]\n",
    "        )\n",
    "        print(self.id_counter)\n",
    "        self.id_counter += len(chunks)\n",
    "\n",
    "\n",
    "    def get_all_entries(self) -> dict:\n",
    "        \"\"\"Get all entries from the database.\n",
    "        Returns:\n",
    "            dict: Dictionary containing all entries in the database.\n",
    "        \"\"\"\n",
    "        return self.chat_db.get()\n",
    "    \n",
    "\n",
    "def clear_db(self, reinitialize:bool = True):\n",
    "    \"\"\"\n",
    "    Clear the database.\n",
    "    Args:\n",
    "        reinitialize (bool): Whether to reinitialize the database after clearing.\n",
    "    \"\"\"\n",
    "    self.client.delete_collection(self.chat_db.name)\n",
    "\n",
    "    # if reinitialize\n",
    "    if reinitialize:\n",
    "        self.__init__(self.chat_db_name, self.model_name)\n",
    "\n",
    "def query_db(self, query_text:str, n_results: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Query the database.\n",
    "    Args:\n",
    "        query_text (str): The query text.\n",
    "        n_results (int): Number of results to return.\n",
    "    Returns:\n",
    "        dict: Dictionary containing the most similar results of the query.\n",
    "    \"\"\"\n",
    "    return self.chat_db.query(query_texts = [query_text], n_results = n_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80006b6b",
   "metadata": {},
   "source": [
    "Add chunks to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9000f760",
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateIDError",
     "evalue": "Expected IDs to be unique, found duplicates of: chunk_1 in add.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDuplicateIDError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:227\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m validate_record_set_contains_any(record_set=add_records, contains_any={\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/types.py:249\u001b[39m, in \u001b[36mvalidate_insert_record_set\u001b[39m\u001b[34m(record_set)\u001b[39m\n\u001b[32m    247\u001b[39m validate_base_record_set(record_set)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/types.py:665\u001b[39m, in \u001b[36mvalidate_ids\u001b[39m\u001b[34m(ids)\u001b[39m\n\u001b[32m    664\u001b[39m         message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected IDs to be unique, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_dups\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m duplicated IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors.DuplicateIDError(message)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[31mDuplicateIDError\u001b[39m: Expected IDs to be unique, found duplicates of: chunk_1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDuplicateIDError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m doc_db = DocumentDB(name=\u001b[33m\"\u001b[39m\u001b[33mpaper_db4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdoc_db\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_chunks_to_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_idxs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mDocumentDB.add_chunks_to_db\u001b[39m\u001b[34m(self, chunks, doc_idxs, metadata)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_chunks_to_db\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunks:\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], doc_idxs:\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], metadata:\u001b[38;5;28mdict\u001b[39m={}):\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    Add chunks to the database.\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m        metadata (dict): Metadata to be added to each chunk.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_db\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdoc_idx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc_idxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunk_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid_counter\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m.id_counter)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m.id_counter += \u001b[38;5;28mlen\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/models/Collection.py:80\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     47\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     58\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m \n\u001b[32m     78\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     add_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._add(\n\u001b[32m     90\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m     91\u001b[39m         ids=add_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m     98\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:98\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg).with_traceback(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:95\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     97\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/models/CollectionCommon.py:227\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    217\u001b[39m add_records = normalize_insert_record_set(\n\u001b[32m    218\u001b[39m     ids=ids,\n\u001b[32m    219\u001b[39m     embeddings=embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m     uris=uris,\n\u001b[32m    224\u001b[39m )\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m validate_record_set_contains_any(record_set=add_records, contains_any={\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/types.py:249\u001b[39m, in \u001b[36mvalidate_insert_record_set\u001b[39m\u001b[34m(record_set)\u001b[39m\n\u001b[32m    246\u001b[39m _validate_record_set_length_consistency(record_set)\n\u001b[32m    247\u001b[39m validate_base_record_set(record_set)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43mvalidate_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    251\u001b[39m     validate_metadatas(record_set[\u001b[33m\"\u001b[39m\u001b[33mmetadatas\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/chromadb/api/types.py:665\u001b[39m, in \u001b[36mvalidate_ids\u001b[39m\u001b[34m(ids)\u001b[39m\n\u001b[32m    661\u001b[39m         example_string = (\n\u001b[32m    662\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(examples[:\u001b[32m5\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ..., \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(examples[-\u001b[32m5\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    663\u001b[39m         )\n\u001b[32m    664\u001b[39m         message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected IDs to be unique, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_dups\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m duplicated IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors.DuplicateIDError(message)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[31mDuplicateIDError\u001b[39m: Expected IDs to be unique, found duplicates of: chunk_1 in add."
     ]
    }
   ],
   "source": [
    "doc_db = DocumentDB(name=\"paper_db4\")\n",
    "doc_db.add_chunks_to_db(chunks = text_chunks, doc_idxs = doc_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
